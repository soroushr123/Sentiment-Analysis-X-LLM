{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055462ab",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac7d79",
   "metadata": {},
   "source": [
    "The libraries that are necessary to import the data from Twitter API are the followings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4e1e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ecc661",
   "metadata": {},
   "source": [
    "Before initiating the data extraction process from Twitter it is important to make a developer account on Twitter and get the required credentials to be able to extract data properly from Twitter. Below is the list of credentials:\n",
    "- API_KEY\n",
    "- API_KEY_SECRET\n",
    "- BEARER_TOKEN\n",
    "- ACCESS_TOKEN\n",
    "- ACCESS_TOKEN_KEY\n",
    "\n",
    "For the purpose of this project, we ask a research and academic permission from Twitter to have access to the full-archive of Twitter database as the regular Twitter developer account only allows the user to extract data from the past 30 days.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52be3e1",
   "metadata": {},
   "source": [
    "# Extracting Tweet Data for the 42nd Federal Election"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455450a",
   "metadata": {},
   "source": [
    "Using the mentioned credentials and **Tweepy** library we can connect to Twitter API to extract the data.\n",
    "\n",
    "The list of all tweet IDs with the official hashtag for the 42nd federal election of Canada (#elxn42) were previously extracted and provided for free on the following link at Canadian Dataverse Ripository:\n",
    "\n",
    "https://borealisdata.ca/dataset.xhtml?persistentId=hdl:10864/11310\n",
    "\n",
    "There are different files available in which the only dataset that is useful for us is the tweet IDs which are also provided in the following path: \n",
    "\n",
    "**Data\\42nd election\\elxn42-tweet-ids.txt**\n",
    "\n",
    "By using the Oauth Handler from Tweepy library and providing hte following credentials, we can connect to the API and extract the data with the time-limit for data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b0f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE CREDENTIALS FOR THIS PART IS GIVEN EXCLUSIVELY TO THIS USER AND FOR SECURITY REASONS\n",
    "# PLEASE USE YOUR OWN API CREDENTIALS IF YOU WOULD LIKE TO RUN THIS CODE\n",
    "\n",
    "API_KEY = 'YOU API KEY'\n",
    "API_KEY_SECRET = 'YOUR API KEY SECRET'\n",
    "BEARER_TOKEN = 'YOUR BEARER TOKEN'\n",
    "ACCESS_TOKEN = 'YOUR ACCESS TOKEN'\n",
    "ACCESS_TOKEN_KEY = 'YOUR ACCESS TOKEN KEY'\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_KEY_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_KEY)\n",
    "api = tweepy.API(auth, wait_on_rate_limit= True)\n",
    "\n",
    "\n",
    "# Create empty DataFrame append data to it\n",
    "elnx42 = pd.DataFrame(columns=['Tweet ID', 'Tweet Date', 'Full Text', 'Likes_count', 'Retweet_count', 'Author name', 'Author ID', 'Author Follower', 'Author Friends', 'Retweet_status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ec307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of IDs to run for data extraction\n",
    "ids_total = pd.read_csv('Data/42nd election/elxn42-tweet-ids.txt', names = ['Tweet ID'])\n",
    "ids = ids_total.sample(frac=0.03, replace=False, random_state=18)\n",
    "\n",
    "\n",
    "ids.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(ids['Tweet ID']):\n",
    "    elnx42.loc[i,'Tweet ID'] = ids['Tweet ID'][i]\n",
    "    \n",
    "    try:\n",
    "        status = api.get_status(ids['Tweet ID'][i], tweet_mode = \"extended\")\n",
    "        elnx42.loc[i,'Tweet Date'] = status.created_at\n",
    "        elnx42.loc[i,'Full Text'] = status.full_text\n",
    "        elnx42.loc[i,'Likes_count'] = status.favorite_count\n",
    "        elnx42.loc[i,'Retweet_count'] = status.retweet_count\n",
    "        elnx42.loc[i,'Author name'] = status.author.name\n",
    "        elnx42.loc[i,'Author ID'] = status.author.id\n",
    "        elnx42.loc[i,'Author Follower'] = status.author.followers_count\n",
    "        elnx42.loc[i,'Author Friends'] = status.author.friends_count\n",
    "        elnx42.loc[i,'Retweet_status'] = status.retweeted\n",
    "    except:\n",
    "        elnx42.loc[i,'Tweet Date'] = 0\n",
    "        elnx42.loc[i,'Full Text'] = 0\n",
    "        elnx42.loc[i,'Likes_count'] = 0\n",
    "        elnx42.loc[i,'Retweet_count'] = 0\n",
    "        elnx42.loc[i,'Author name'] = 0\n",
    "        elnx42.loc[i,'Author ID'] = 0\n",
    "        elnx42.loc[i,'Author Follower'] = 0\n",
    "        elnx42.loc[i,'Author Friends'] = 0\n",
    "        elnx42.loc[i,'Retweet_status'] = 0\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        elnx42.to_csv('Data/backup4.csv')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bb078d",
   "metadata": {},
   "source": [
    "Due to the local system power limit, the data have been extracted within 4 step through the week, in which each step took around 15 to 16 hours for extracting 250K lines of data.\n",
    "Using the following sample code, we made sure that we are not picking the same IDs twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8afc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_total = pd.read_csv(r'D:\\Brainstation\\Capstone\\42nd election\\elxn42-tweet-ids.txt', names = ['Tweet ID'])\n",
    "# backup1 = pd.read_csv('backup.csv')\n",
    "ids_remaining = ids_total.merge(df, how = 'left', left_on = 'Tweet ID', right_on = 'Tweet ID')\n",
    "ids_remaining = ids_remaining[ids_remaining['Full Text'].isna()]\n",
    "\n",
    "ids_remaining = pd.DataFrame(ids_remaining['Tweet ID'], columns = ['Tweet ID'])\n",
    "ids_remaining.head()\n",
    "ids = ids_remaining.sample(frac=0.03, replace=False, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a86a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "072532ce",
   "metadata": {},
   "source": [
    "# Extracting Tweet Data for the 43rd Federal Election"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e20ffc",
   "metadata": {},
   "source": [
    "The same set of tweet IDs for the 43rd federal election has also been downloaded from the same website using the following link:\n",
    "\n",
    "https://borealisdata.ca/dataset.xhtml?persistentId=doi:10.5683/SP2/QAMPPI\n",
    "\n",
    "This dataset will only be used for the purpose of testing the whole pipeline and see if it can predict the winner properly or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc86fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "elnx43 = pd.DataFrame(columns=['Tweet ID', 'Tweet Date', 'Full Text', 'Likes_count', 'Retweet_count', 'Author name', 'Author ID', 'Author Follower', 'Author Friends', 'Retweet_status'])\n",
    "\n",
    "ids_total_43rd = pd.read_csv('Data/43rd election/elxn43-ids.txt', names = ['Tweet ID'])\n",
    "ids_43rd = ids_total_43rd.sample(frac=0.0001, replace=False, random_state=18)\n",
    "\n",
    "\n",
    "ids_43rd.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cc35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(ids_43rd['Tweet ID']):\n",
    "    elnx43.loc[i,'Tweet ID'] = ids_43rd['Tweet ID'][i]\n",
    "    \n",
    "    try:\n",
    "        status = api.get_status(ids_43rd['Tweet ID'][i], tweet_mode = \"extended\")\n",
    "        elnx43.loc[i,'Tweet Date'] = status.created_at\n",
    "        elnx43.loc[i,'Full Text'] = status.full_text\n",
    "        elnx43.loc[i,'Likes_count'] = status.favorite_count\n",
    "        elnx43.loc[i,'Retweet_count'] = status.retweet_count\n",
    "        elnx43.loc[i,'Author name'] = status.author.name\n",
    "        elnx43.loc[i,'Author ID'] = status.author.id\n",
    "        elnx43.loc[i,'Author Follower'] = status.author.followers_count\n",
    "        elnx43.loc[i,'Author Friends'] = status.author.friends_count\n",
    "        elnx43.loc[i,'Retweet_status'] = status.retweeted\n",
    "    except:\n",
    "        elnx43.loc[i,'Tweet Date'] = 0\n",
    "        elnx43.loc[i,'Full Text'] = 0\n",
    "        elnx43.loc[i,'Likes_count'] = 0\n",
    "        elnx43.loc[i,'Retweet_count'] = 0\n",
    "        elnx43.loc[i,'Author name'] = 0\n",
    "        elnx43.loc[i,'Author ID'] = 0\n",
    "        elnx43.loc[i,'Author Follower'] = 0\n",
    "        elnx43.loc[i,'Author Friends'] = 0\n",
    "        elnx43.loc[i,'Retweet_status'] = 0\n",
    "    \n",
    "elnx43.to_csv('Data/test_elnx43.csv')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c4909a",
   "metadata": {},
   "source": [
    "# Importing Libraries for Data Cleaning and Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f97ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import IntProgress\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from functools import partial\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30324e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91805027",
   "metadata": {},
   "source": [
    "# Importing Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4269eb",
   "metadata": {},
   "source": [
    "before heading through the data cleaning and labeling, we need to import the datasets and merging them together. The total number of 250K tweets were extracted from twitter in which about 100K of those are not available at the moment of this analysis. This is due to the fact the data that we are working on, are originally from 2015. Since that time, some tweets might be deleted, the some user accounts might get closed which cause a null return from Twitter API. We initially replace those values with 0 in the raw dataset. This makes the process of dropping those rows easier as follow.\n",
    "Also the process parliamentarian dataset is imported for labeling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cdec5bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Temp\\ipykernel_18136\\1807307996.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = Tweets_1.append(Tweets_2, ignore_index= True)\n",
      "C:\\Users\\sorou\\AppData\\Local\\Temp\\ipykernel_18136\\1807307996.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(Tweets_3, ignore_index= True)\n",
      "C:\\Users\\sorou\\AppData\\Local\\Temp\\ipykernel_18136\\1807307996.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(Tweets_4, ignore_index= True)\n"
     ]
    }
   ],
   "source": [
    "# backup files from twitter API\n",
    "# Merging all the collected tweets into one DataFrame\n",
    "Tweets_1 = pd.read_csv('Data/Tweets_1.csv')\n",
    "Tweets_2 = pd.read_csv('Data/Tweets_2.csv')\n",
    "Tweets_3 = pd.read_csv('Data/Tweets_3.csv')\n",
    "Tweets_4 = pd.read_csv('Data/Tweets_4.csv')\n",
    "\n",
    "df = Tweets_1.append(Tweets_2, ignore_index= True)\n",
    "df = df.append(Tweets_3, ignore_index= True)\n",
    "df = df.append(Tweets_4, ignore_index= True)\n",
    "df.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "\n",
    "# Removing the deleted, or generally not available tweets from the Dataset\n",
    "df = df[df['Full Text'] != '0']\n",
    "\n",
    "\n",
    "# parliamentarian info and their parties for \n",
    "parties_final = pd.read_csv('Data/parties_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de45a3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb9e08c",
   "metadata": {},
   "source": [
    "# Split the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce78b2e7",
   "metadata": {},
   "source": [
    "Before proceed with any data cleaning process, we wish to exclude a 20% portion of the total data we have to have them separate as a final test set predict the labels and sentiment. This can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fb24ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.sample(frac = 0.20, replace = False, random_state=10)\n",
    "df_train = df.drop(df_test.index)\n",
    "\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f84216c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Tweet Date</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Likes_count</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Follower</th>\n",
       "      <th>Author Friends</th>\n",
       "      <th>Retweet_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641648154945961984</td>\n",
       "      <td>2015-09-09 16:23:36+00:00</td>\n",
       "      <td>What the heck is going on with the NDP? Doesn'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Lynn Carleton</td>\n",
       "      <td>2811644853</td>\n",
       "      <td>1002</td>\n",
       "      <td>381</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>655926104289619972</td>\n",
       "      <td>2015-10-19 01:59:04+00:00</td>\n",
       "      <td>RT @APLawToronto: It's not how you start that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Ronnie (Wear a Mask!) Zwierz ðŸ‡¨ðŸ‡¦</td>\n",
       "      <td>2375728898</td>\n",
       "      <td>3487</td>\n",
       "      <td>339</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>643417181410193408</td>\n",
       "      <td>2015-09-14 13:33:04+00:00</td>\n",
       "      <td>Meet @SheriRBenson @NDP_HQ candidate 4 #Saskat...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ProudPolitics Canada</td>\n",
       "      <td>577727470</td>\n",
       "      <td>1732</td>\n",
       "      <td>1019</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>654093831542059009</td>\n",
       "      <td>2015-10-14 00:38:16+00:00</td>\n",
       "      <td>RT @MikeHudema: World now talking about #Harpe...</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>Wayne Johnston</td>\n",
       "      <td>550253210</td>\n",
       "      <td>5248</td>\n",
       "      <td>5391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>637043425972371456</td>\n",
       "      <td>2015-08-27 23:26:03+00:00</td>\n",
       "      <td>RT @joeldey: Spotted at Quebec and Terminal in...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>John Coulbourn</td>\n",
       "      <td>270491583</td>\n",
       "      <td>848</td>\n",
       "      <td>806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID                 Tweet Date  \\\n",
       "0  641648154945961984  2015-09-09 16:23:36+00:00   \n",
       "1  655926104289619972  2015-10-19 01:59:04+00:00   \n",
       "2  643417181410193408  2015-09-14 13:33:04+00:00   \n",
       "3  654093831542059009  2015-10-14 00:38:16+00:00   \n",
       "4  637043425972371456  2015-08-27 23:26:03+00:00   \n",
       "\n",
       "                                           Full Text  Likes_count  \\\n",
       "0  What the heck is going on with the NDP? Doesn'...            1   \n",
       "1  RT @APLawToronto: It's not how you start that ...            0   \n",
       "2  Meet @SheriRBenson @NDP_HQ candidate 4 #Saskat...            3   \n",
       "3  RT @MikeHudema: World now talking about #Harpe...            0   \n",
       "4  RT @joeldey: Spotted at Quebec and Terminal in...            0   \n",
       "\n",
       "   Retweet_count                      Author name   Author ID  \\\n",
       "0              0                    Lynn Carleton  2811644853   \n",
       "1             11  Ronnie (Wear a Mask!) Zwierz ðŸ‡¨ðŸ‡¦  2375728898   \n",
       "2              3             ProudPolitics Canada   577727470   \n",
       "3             75                   Wayne Johnston   550253210   \n",
       "4             36                   John Coulbourn   270491583   \n",
       "\n",
       "   Author Follower  Author Friends Retweet_status  \n",
       "0             1002             381          False  \n",
       "1             3487             339          False  \n",
       "2             1732            1019          False  \n",
       "3             5248            5391          False  \n",
       "4              848             806          False  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55a46313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a backup of the train set\n",
    "df_train.to_csv('Data/df_train_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "19bafa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a backup of the test set\n",
    "df_test.to_csv('Data/df_test_raw.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff5e286",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9c24e",
   "metadata": {},
   "source": [
    "the published tweets on Twitter can contain lots of unwanted and unnecessary information for the analysis in this project. some of these information come directly from the tweets and some other are the handlers and other notations that gets visible while extracting the data twitter API .some of them includes the following:\n",
    "- Lowercase the texts\n",
    "- twitter return handles\n",
    "- URL links \n",
    "- official hashtags including `#elxn42`\n",
    "\n",
    "the following code explain the procedure to deal with the mentioned issues. one other important step that is added is to get back the words to their root format (e.g. helping --> help, etc.) to both reduce the dimentionality of the dataset after tokenizing and also help the process of data labeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd969dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General function for removing unnecessary information that is used in the following functions\n",
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i,'', input_txt)\n",
    "    return input_txt\n",
    "\n",
    "def clean_tweets(tweets):\n",
    "    #remove twitter Return handles (RT @xxx:)*\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"RT @[\\w]*:\")\n",
    "\n",
    "    #remove URL links (httpxxx)*\n",
    "    tweets = np.vectorize(remove_pattern)(tweets, \"https?://[A-Za-z0-9./]*\")\n",
    "    \n",
    "    #remove official hashtags including elxn42\n",
    "    tweets = np.core.defchararray.replace(tweets, \"#elxn42\", \"\")\n",
    "    tweets = np.core.defchararray.replace(tweets, \"#cdnpoli\", \"\")\n",
    "    tweets = np.core.defchararray.replace(tweets, \"#canada\", \"\")\n",
    "\n",
    "    return tweets\n",
    "\n",
    "def lemmatize_text(tweets):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(tweets)]\n",
    "\n",
    "def collapse_list_to_string(string_list):\n",
    "    # This is to join back together the text data into a single string\n",
    "    return ' '.join(string_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5046577b",
   "metadata": {},
   "source": [
    "Text lemmatization is the process of reducing a word to its base or dictionary form, known as a lemma. The base form or lemma of a word is its most basic, canonical or meaningful form. For example, the lemma of the word \"running\" is \"run\", and the lemma of the word \"mice\" is \"mouse\".\n",
    "\n",
    "Lemmatization is often used in natural language processing (NLP) to normalize text and reduce the complexity of words, so that they can be analyzed or compared more easily. It is different from stemming, which is another technique to reduce words to their base form, but does so by simply removing the suffixes from a word, without taking into account the part of speech or context.\n",
    "\n",
    "Lemmatization involves using a linguistic rule-based system to analyze a word and determine its lemma, based on the word's part of speech (noun, verb, adjective, adverb, etc.) and context. This can involve looking up the word in a dictionary, applying morphological analysis or using machine learning algorithms to predict the correct lemma.\n",
    "\n",
    "Overall, lemmatization is a powerful tool in natural language processing and is used in various applications such as text classification, information retrieval, sentiment analysis, and more.\n",
    "\n",
    "Below is the cleaned dataset which are stored in a new column called `Full Text2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4cce721e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "\n",
    "df_train['Full Text'] = df_train['Full Text'].str.lower()\n",
    "df_train['Full Text2'] = clean_tweets(df_train['Full Text'])\n",
    "df_train['Full Text2'] = df_train['Full Text2'].astype(str).apply(lemmatize_text)\n",
    "df_train['Full Text2'] = df_train['Full Text2'].apply(collapse_list_to_string)\n",
    "df_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f44f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06e5bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a column for political party to the data set with none value\n",
    "# The none values will be replaced in multiple steps until the end of this notebook\n",
    "df_train['party'] = 'none'\n",
    "\n",
    "# make three datasets for liberal, conservative and ndp names from the parliament members dataset\n",
    "liberal_party = parties_final[parties_final['party'] == 'liberal']\n",
    "conservative_party = parties_final[parties_final['party'] == 'conservative']\n",
    "ndp_party = parties_final[parties_final['party'] == 'ndp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a6643c",
   "metadata": {},
   "source": [
    "The following cell will check every row of our original dataset with the set of names of the above defined datasets for political parties. If any of the tweet texts contains a word from any of the above datasets, then the assumption is that the tweet is talking about that specific party. E.g. having the name **justintrudeau** means the tweet is related to liberal party.\n",
    "In this way we can use the labeled tweets as another training set to fit a model, and that model predict the political party label of the unlabeled tweets. In other word, we get the help of a semi-supervised learning system to cathegorize our dataset based on the political parties.\n",
    "\n",
    "**The below code can take at least 10 Hours to run. For the ease of analysis, the result of the following cell is saved and provided in the Data folder of this project**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c4a6c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell will take couple of hours to run\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    if any(ele in df_train.loc[i,'Full Text'] for ele in liberal_party['Name']):\n",
    "        df_train.loc[i,'party'] = 'liberal'\n",
    "    elif any(ele in df_train.loc[i,'Full Text'] for ele in conservative_party['Name']):\n",
    "        df_train.loc[i,'party'] = 'conservative'\n",
    "    elif any(ele in df_train.loc[i,'Full Text'] for ele in ndp_party['Name']):\n",
    "        df_train.loc[i,'party'] = 'ndp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e60cd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save a Backup of the preprocessing to the folder\n",
    "df_train.to_csv('Data/df_train_labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4abaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can load the backup file and continue from here on\n",
    "df_train_labeled = pd.read_csv('Data/df_train_labeled.csv')\n",
    "df_train_labeled.drop('Unnamed: 0', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc387ee9",
   "metadata": {},
   "source": [
    "# TF-IDF Vectorizer and Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351c9471",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequency-Inverse Document Frequency) is a numerical statistic that is used to reflect the importance of a word in a document or corpus (collection of documents). It is a popular technique used in text mining, information retrieval, and natural language processing.\n",
    "\n",
    "TF-IDF is calculated by multiplying two values: term frequency (TF) and inverse document frequency (IDF).\n",
    "- Term frequency (TF) is the number of times a word (term) appears in a document. The more times a word appears in a document, the more important it is assumed to be in that document.\n",
    "\n",
    "- Inverse document frequency (IDF) is a measure of how important a word is in the entire corpus. IDF is calculated by taking the logarithm of the ratio of the total number of documents in the corpus to the number of documents containing the word. The less frequently a word appears in the corpus, the higher its IDF value.\n",
    "\n",
    "The TF-IDF vectorizer is useful for text classification and other natural language processing tasks because it can convert raw text data into a format that can be used by machine learning algorithms to make predictions. By using TF-IDF scores to represent text documents, machine learning algorithms can more easily identify patterns and relationships between words, and use these to make accurate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4e677",
   "metadata": {},
   "source": [
    "Ensemble learning is a machine learning technique that involves combining multiple models to improve prediction accuracy and robustness. Instead of relying on a single model to make predictions, ensemble learning involves training multiple models on the same dataset and then aggregating their predictions in some way to make a final prediction.\n",
    "\n",
    "There are several different types of ensemble learning techniques, but two of the most common are:\n",
    "\n",
    "- Bagging: In bagging (short for bootstrap aggregating), multiple models are trained on different subsets of the data, and their predictions are averaged to make a final prediction. Bagging is commonly used with decision trees, where each model is trained on a random subset of the features, to reduce overfitting.\n",
    "\n",
    "- Boosting: In boosting, multiple weak models are trained sequentially, with each new model learning from the errors of the previous model. The final prediction is then based on a weighted average of the predictions of all the models. Boosting is commonly used with decision trees, neural networks, and other models.\n",
    "\n",
    "Ensemble learning can lead to significant improvements in prediction accuracy, especially when used with weak models that are prone to overfitting or underfitting. It can also help to improve model robustness by reducing the impact of individual model errors or biases.\n",
    "\n",
    "Here we are going with the **Bagging** approach for our label prediction.\n",
    "\n",
    "**Be careful with running the following code, it will take over 6 hours depending on your computation power, the saved model is provided in the Model folder for your ease**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb3ff6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "classes = df_train_labeled['party'].values\n",
    "import pandas as pd\n",
    "\n",
    "# Split the X and y (target)\n",
    "X = df_train_labeled[(df_train_labeled['Full Text2'].notna()) & (df_train_labeled['party'] != 'none')]['Full Text2']\n",
    "y = df_train_labeled[(df_train_labeled['Full Text2'].notna()) & (df_train_labeled['party'] != 'none')]['party']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the TF-IDF vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words = \"english\")\n",
    "\n",
    "# Vectorize the training data\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n",
    "# Define the classifiers\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "mnb = MultinomialNB()\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define the parameters for GridSearchCV for each classifier\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [20, 50, 100]\n",
    "}\n",
    "\n",
    "mnb_params = {\n",
    "    'alpha': [0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "gnb_params = {\n",
    "    'var_smoothing': [1e-6, 1e-5, 1e-4]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV object for each classifier\n",
    "rf_grid = GridSearchCV(rf, rf_params, cv=5)\n",
    "mnb_grid = GridSearchCV(mnb, mnb_params, cv=5)\n",
    "gnb_grid = GridSearchCV(gnb, gnb_params, cv=5)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data for each classifier\n",
    "rf_grid.fit(X_train_tfidf, y_train)\n",
    "mnb_grid.fit(X_train_tfidf, y_train)\n",
    "gnb_grid.fit(X_train_tfidf.toarray(), y_train)\n",
    "\n",
    "# Print the best parameters and best score for each classifier\n",
    "print('Random Forest: Best parameters:', rf_grid.best_params_)\n",
    "print('Random Forest: Best score:', rf_grid.best_score_)\n",
    "print('Multinomial Naive Bayes: Best parameters:', mnb_grid.best_params_)\n",
    "print('Multinomial Naive Bayes: Best score:', mnb_grid.best_score_)\n",
    "print('Gaussian Naive Bayes: Best parameters:', gnb_grid.best_params_)\n",
    "print('Gaussian Naive Bayes: Best score:', gnb_grid.best_score_)\n",
    "\n",
    "# Get the best estimator for each classifier\n",
    "best_rf = rf_grid.best_estimator_\n",
    "best_mnb = mnb_grid.best_estimator_\n",
    "best_gnb = gnb_grid.best_estimator_\n",
    "\n",
    "# Define the voting classifier\n",
    "voting_clf = VotingClassifier(estimators=[('rf', best_rf), ('mnb', best_mnb), ('gnb', best_gnb)])\n",
    "\n",
    "# Get the cross validation score of the voting classifier\n",
    "scores = cross_val_score(voting_clf, tfidf.transform(X).todense(), y, cv=5)\n",
    "\n",
    "# Print the cross validation scores\n",
    "print('Cross validation scores:', scores)\n",
    "\n",
    "# Fit the voting classifier to the training data\n",
    "voting_clf.fit(X_train_tfidf.todense(), y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = voting_clf.predict(tfidf.transform(X_test).todense())\n",
    "\n",
    "# Print the classification report and accuracy score\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea2595",
   "metadata": {},
   "source": [
    "Random Forest, Multinomial Naive Bayes, and Gaussian Naive Bayes are all popular algorithms used in ensemble learning for data labeling. Each of these algorithms has unique characteristics that make it suitable for different types of data and applications.\n",
    "\n",
    "#### Random Forest:\n",
    "Random Forest is a type of decision tree-based algorithm that uses an ensemble of decision trees to make predictions. Each decision tree is trained on a random subset of the features and data, making it less prone to overfitting and more robust to outliers. Random Forest can be used for both classification and regression tasks and has proven to be an effective algorithm for a wide range of applications.\n",
    "\n",
    "#### Multinomial Naive Bayes:\n",
    "Multinomial Naive Bayes is a probabilistic algorithm that is particularly suited for text classification tasks. It is based on Bayes' theorem and assumes that the probability of each feature value is conditionally independent of all other features given the class variable. This assumption allows the algorithm to work well with high-dimensional datasets such as text data.\n",
    "\n",
    "#### Gaussian Naive Bayes:\n",
    "Gaussian Naive Bayes is a variant of Naive Bayes that is used for continuous data. It assumes that the features are normally distributed and independent of each other given the class variable. Gaussian Naive Bayes can be used for both classification and regression tasks and is particularly suited for applications with continuous data such as sensor data or image data.\n",
    "\n",
    "In an ensemble learning setting, Gaussian Naive Bayes can be combined with other algorithms to improve the accuracy and robustness of the model. One common approach is to use Gaussian Naive Bayes as a base model and combine it with other models such as Random Forest or Multinomial Naive Bayes to create a more diverse ensemble.\n",
    "\n",
    "Overall, the choice of algorithm(s) for ensemble learning depends on the specific characteristics of the dataset and the application requirements. By combining multiple models, ensemble learning can help to improve the accuracy and robustness of the model, leading to better performance and more reliable predictions. The choice of these three algorithm has been made according to the research papers in this area.\n",
    "\n",
    "The next step is to run the cross-validation score and accuracy test on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ce9967b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with the following code, we have have access to the paramteres of each model in the voting classifier\n",
    "best_rf = voting_clf.named_estimators.rf\n",
    "best_mnb = voting_clf.named_estimators.mnb\n",
    "best_gnb = voting_clf.named_estimators.gnb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f500096",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.92064195 0.91698949 0.91853901 0.91743221 0.91875138]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores: [0.91228556 0.90896514 0.90702822 0.91256226 0.91033624]\n"
     ]
    }
   ],
   "source": [
    "#  We can see the cross validation score of the model through:\n",
    "scores = cross_val_score(voting_clf, X_train_tfidf.todense(), y_train, cv=5)\n",
    "\n",
    "\n",
    "print('Cross validation scores:', scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836bb0de",
   "metadata": {},
   "source": [
    "The score of a voting classifier represents its overall accuracy in predicting the correct class labels for a given set of data. This score is typically measured using a metric such as accuracy, precision, recall, or F1 score, depending on the specific requirements of the problem at hand. The score of a voting classifier can be used to evaluate its performance and compare it against other classifiers or models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9f77270",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "conservative       0.91      0.90      0.91      2593\n",
      "     liberal       0.91      0.98      0.94      4764\n",
      "         ndp       0.97      0.77      0.86      1678\n",
      "\n",
      "    accuracy                           0.92      9035\n",
      "   macro avg       0.93      0.88      0.90      9035\n",
      "weighted avg       0.92      0.92      0.92      9035\n",
      "\n",
      "Accuracy: 0.9182069728832318\n"
     ]
    }
   ],
   "source": [
    "y_pred = voting_clf.predict(tfidf.transform(X_test).todense())\n",
    "\n",
    "# Print the classification report and accuracy score\n",
    "print('Classification report:\\n', classification_report(y_test, y_pred))\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36602404",
   "metadata": {},
   "source": [
    "The classification report shows the precision, recall, and F1-score of a classifier for each class. In this case, we have a three-class problem with precision scores of 0.91, 0.91, and 0.97 for the first, second, and third classes, respectively. This indicates that the classifier is quite accurate in predicting the correct class for each instance, particularly for the third class.\n",
    "\n",
    "The recall scores are 0.90, 0.98, and 0.77 for the first, second, and third classes, respectively. This indicates that the classifier is able to correctly identify most instances of the second class, but is less effective at identifying instances of the first and third classes.\n",
    "\n",
    "The F1-scores are 0.91, 0.94, and 0.86 for the first, second, and third classes, respectively. The F1-score is the harmonic mean of precision and recall, and provides a measure of the overall accuracy of the classifier for each class. The highest F1-score is obtained for the second class, indicating that the classifier is most effective at predicting this class.\n",
    "\n",
    "Overall, the classification report suggests that the classifier is quite accurate in predicting the correct class labels for the second class, but is less effective for the first and third classes. The accuracy score of 0 indicates that the classifier did not correctly predict any instances, but this is likely due to the fact that the accuracy score was calculated on a specific subset of the data and may not be representative of the overall performance of the classifier. Further analysis and evaluation would be needed to fully assess the performance of the classifier for this three-class problem.\n",
    "\n",
    "On the other hand, the best practice is to get the confusion matrix for a balanced amount of data through the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2df266a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[2328  247   18]\n",
      " [  68 4674   22]\n",
      " [ 152  232 1294]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af359f8d",
   "metadata": {},
   "source": [
    "In order to make it easy to run the model at anytime and saving time, we use pickle library to get a export and backup of te trained model and its parameter and future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "544ddcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(voting_clf, open(\"Model/model_clf_ensemble\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d94af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tfidf, open(\"Model/tfidf\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ec2a2",
   "metadata": {},
   "source": [
    "As the model provide with good score and accuracy, we pass in the unlabeled tweets of the training set to categorize the political party that their are talking about.\n",
    "Once this step is done, we will have train dataset (which is 80% of the total data that we initially collect) and we can move them for the sentimental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2f5c708a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_predict = df_train_labeled[(df_train_labeled['Full Text2'].notna()) & (df_train_labeled['party'] == 'none')]['Full Text2']\n",
    "\n",
    "X_predict_tfidf=tfidf.transform(X_predict)\n",
    "\n",
    "df_party_predict=voting_clf.predict(X_predict_tfidf.todense())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "027920c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily splitting the the training data into labeled and not labeled\n",
    "df_known_label = df_train_labeled[(df_train_labeled['Full Text2'].notna()) & (df_train_labeled['party'] != 'none')]\n",
    "df_unknown_label = df_train_labeled[(df_train_labeled['Full Text2'].notna()) & (df_train_labeled['party'] == 'none')]\n",
    "                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d7bf8ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the predicted y (political party label in the above cell df_party_predict) to the unlabeled data\n",
    "counter = 0\n",
    "for i in test.index:\n",
    "    df_unknown_label.loc[i,'party'] = df_party_predict[counter]\n",
    "    \n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "88c61d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Temp\\ipykernel_18136\\1928774303.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_train_for_transformer = df_known_label.append(df_unknown_label)\n"
     ]
    }
   ],
   "source": [
    "# merging the the splitted dataset together to get the full training dataset again\n",
    "df_train_for_transformer = df_known_label.append(df_unknown_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46606e97",
   "metadata": {},
   "source": [
    "The last step is to save the data into a csv file to pass it to the Sentimental analysis notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7999e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_for_transformer = df_train_for_transformer.sort_index()\n",
    "df_train_for_transformer.to_csv('Data/df_train_for_transformer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff94d973",
   "metadata": {},
   "source": [
    "# Test Dataset prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591441c3",
   "metadata": {},
   "source": [
    "In order to see of the model can provide a good estimate on the overal election results outcome, we feed the non-seen test set that we initially split from the raw dataset. All the visualizations are provided after the sentimental analysis in a different notebook. Here we only run the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5cbc51d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Tweet Date</th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Likes_count</th>\n",
       "      <th>Retweet_count</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Author ID</th>\n",
       "      <th>Author Follower</th>\n",
       "      <th>Author Friends</th>\n",
       "      <th>Retweet_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656289970479611904</td>\n",
       "      <td>2015-10-20 02:04:56+00:00</td>\n",
       "      <td>RT @HuffPostCanada: #Elxn42\\nEarly numbers in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>RTCP24 NEWS</td>\n",
       "      <td>204195016</td>\n",
       "      <td>1230</td>\n",
       "      <td>540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>631864164777070592</td>\n",
       "      <td>2015-08-13 16:25:31+00:00</td>\n",
       "      <td>RT @jcallaghan2: #Pierrefonds removing concret...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Jim Crowell</td>\n",
       "      <td>76333343</td>\n",
       "      <td>270</td>\n",
       "      <td>467</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>656312883849113600</td>\n",
       "      <td>2015-10-20 03:35:59+00:00</td>\n",
       "      <td>RT @JJVenky: After being called a â€˜radical ide...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Freshwater fELA</td>\n",
       "      <td>632592632</td>\n",
       "      <td>2662</td>\n",
       "      <td>2302</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>645292291473567744</td>\n",
       "      <td>2015-09-19 17:44:05+00:00</td>\n",
       "      <td>Government should support private-sector inves...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Sun</td>\n",
       "      <td>185269740</td>\n",
       "      <td>2251</td>\n",
       "      <td>380</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656209902499725312</td>\n",
       "      <td>2015-10-19 20:46:47+00:00</td>\n",
       "      <td>I just voted..... did you? #canadavotes #cdnpo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ðŸ¦‹ Jimmy Dean Levi ðŸ’ŽðŸ’Ž ðŸ’Ž</td>\n",
       "      <td>1087785944</td>\n",
       "      <td>1815</td>\n",
       "      <td>1576</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tweet ID                 Tweet Date  \\\n",
       "0  656289970479611904  2015-10-20 02:04:56+00:00   \n",
       "1  631864164777070592  2015-08-13 16:25:31+00:00   \n",
       "2  656312883849113600  2015-10-20 03:35:59+00:00   \n",
       "3  645292291473567744  2015-09-19 17:44:05+00:00   \n",
       "4  656209902499725312  2015-10-19 20:46:47+00:00   \n",
       "\n",
       "                                           Full Text  Likes_count  \\\n",
       "0  RT @HuffPostCanada: #Elxn42\\nEarly numbers in ...            0   \n",
       "1  RT @jcallaghan2: #Pierrefonds removing concret...            0   \n",
       "2  RT @JJVenky: After being called a â€˜radical ide...            0   \n",
       "3  Government should support private-sector inves...            0   \n",
       "4  I just voted..... did you? #canadavotes #cdnpo...            0   \n",
       "\n",
       "   Retweet_count             Author name   Author ID  Author Follower  \\\n",
       "0             21             RTCP24 NEWS   204195016             1230   \n",
       "1              2             Jim Crowell    76333343              270   \n",
       "2              1         Freshwater fELA   632592632             2662   \n",
       "3              0                 The Sun   185269740             2251   \n",
       "4              0  ðŸ¦‹ Jimmy Dean Levi ðŸ’ŽðŸ’Ž ðŸ’Ž  1087785944             1815   \n",
       "\n",
       "   Author Friends Retweet_status  \n",
       "0             540          False  \n",
       "1             467          False  \n",
       "2            2302          False  \n",
       "3             380          False  \n",
       "4            1576          False  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c448ed17",
   "metadata": {},
   "source": [
    "We use the same TF-IDF vectorizer and model to label the test set and save it for the sentimental analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fc0979fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test['Full Text']\n",
    "\n",
    "X_predict_test_tfidf=tfidf.transform(X_test)\n",
    "\n",
    "df_test_party_predict=voting_clf.predict(X_predict_test_tfidf.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a19f9602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['party'] = df_test_party_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ab709771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('Data/df_test_for_transformer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0feb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "145932d5",
   "metadata": {},
   "source": [
    "# Label prediction of the 43rd federal election dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae5b709",
   "metadata": {},
   "source": [
    "It is desired to see if the whole process can predict the result of another Federal of Canada. Thus, the 43rd Federal election tweets that were extracted earlier from the twitter were also fed into the model and labeled using the same model.\n",
    " All the visualization are provided in another notebook after the sentimental analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d256a2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "elxn43 = pd.read_csv('Data/test_elnx43.csv')\n",
    "\n",
    "elxn43 = elxn43[elxn43['Full Text'] != '0']\n",
    "elxn43.reset_index(drop = True, inplace = True)\n",
    "elxn43.drop('Unnamed: 0', axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27042b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "tfidf = pickle.load(open(\"Model/tfidf\", 'rb'))\n",
    "voting_clf = pickle.load(open(\"Model/model_clf_ensemble\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6c67c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n",
      "C:\\Users\\sorou\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:727: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict the labels after vectorizing\n",
    "X_test_elxn43 = elxn43['Full Text']\n",
    "\n",
    "X_predict_test_tfidf_elxn43=tfidf.transform(X_test_elxn43)\n",
    "\n",
    "df_test_party_predict_elxn43=voting_clf.predict(X_predict_test_tfidf_elxn43.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8469099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "elxn43['party'] = df_test_party_predict_elxn43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1faf6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "`elxn43.to_csv('Data/elxn43_labeled_for_transformer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

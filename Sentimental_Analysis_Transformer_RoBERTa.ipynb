{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6ea051",
   "metadata": {},
   "source": [
    "# Importing required libraries for Sentimental Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6f8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "# import vaderSentiment\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "from ipywidgets import IntProgress\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83bd4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5925c65",
   "metadata": {},
   "source": [
    "# Importing Labeled Datasets\n",
    "\n",
    "The following three datasets are all labeled and categorized based on their political party. The Training dataset is the one that we check the final outcome with. If the the model worked properly, it is extected that the Train dataset can give the right overall outcome of the election result. The final expectation is that the model and sentimental analysis process, can leads to the correct outcome for the other two datasets (Test dataset and 43rd election dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41174f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Train set of the 42nd election\n",
    "df_train_for_transformer = pd.read_csv('Data/df_train_for_transformer.csv')\n",
    "df_train_for_transformer.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "df_train_for_transformer = df_train_for_transformer.reset_index()\n",
    "\n",
    "# Importing the Test set of the 42nd election\n",
    "df_test_for_transformer = pd.read_csv('Data/df_test_for_transformer.csv')\n",
    "df_test_for_transformer.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "df_test_for_transformer = df_test_for_transformer.reset_index()\n",
    "\n",
    "# Importing the Data set of the 43nd election\n",
    "elxn43_for_transformer = pd.read_csv('Data/elxn43_labeled_for_transformer.csv')\n",
    "elxn43_for_transformer.drop('Unnamed: 0', axis = 1, inplace=True)\n",
    "elxn43_for_transformer = elxn43_for_transformer.reset_index()\n",
    "\n",
    "# All of the above datrasets are labeled with the ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795a6d1",
   "metadata": {},
   "source": [
    "# Importing the Sentimental Analysis models\n",
    "\n",
    "RoBERTa (Robustly Optimized BERT Pretraining Approach) is a large-scale language model developed by Facebook AI Research (FAIR) in 2019. It is built upon the pre-training approach of the popular BERT (Bidirectional Encoder Representations from Transformers) model, with several modifications to improve its performance. RoBERTa has been trained on a massive corpus of text data, which includes BooksCorpus and English Wikipedia, with a total of 160 GB of uncompressed text data. It has achieved state-of-the-art results on several natural language processing tasks, such as question answering, sentiment analysis, and text classification. The RoBERTa model has also been used as the foundation for several other language models, including ELECTRA, which uses a new training objective to improve efficiency and performance, and GPT-3, which has over 175 billion parameters and is currently the largest language model to date.\n",
    "\n",
    "Here we import and download the parameters of this pre-trained model and use it for our sentimental analysis. The process of importing is as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc61df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ea2f3",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool developed by researchers at the University of Georgia. It is designed to analyze the sentiment of text data, such as social media posts, online reviews, and news articles. VADER uses a lexicon of sentiment-related words and phrases, which are rated according to their emotional valence (positive, negative, or neutral) and intensity. It also incorporates a set of rules to handle contextual features such as negation, punctuation, and capitalization. VADER has been shown to perform well on a variety of sentiment analysis tasks, including sentiment classification, emotion detection, and opinion mining. Its accuracy and ease of use have made it a popular choice for researchers and practitioners in the field of natural language processing.\n",
    "\n",
    "The Main approach for the sentimental analysis of this project is the RoBERTa language model. However, to also have a rough comparison between the machine learning approach and ruled-based approach of sentimental analysis, we get the result of the VADER sentimental through a same process for getting the RoBERTa sentiment into one function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42047d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "884108d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarity_scores_roberta(example):\n",
    "    \"\"\"\n",
    "    This function save the positive, negative and neutrality sentiment of a text into a dictionary.\n",
    "    The text will first get tokenized and formed into aPytorch tensor.\n",
    "    Tokenizer(text example, return_tensor ---> pytorch)\n",
    "    The the model is run and the result is detach into numpy.\n",
    "    The final scores are then saved into a dictionary\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    encoded_text = tokenizer(example, return_tensors='pt')\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {\n",
    "        'roberta_neg' : scores[0],\n",
    "        'roberta_neu' : scores[1],\n",
    "        'roberta_pos' : scores[2]\n",
    "    }\n",
    "    return scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e277d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9872ce",
   "metadata": {},
   "source": [
    "# Running Sentiment Transformer on Training Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b60a89",
   "metadata": {},
   "source": [
    "Here we use `tqdm` library to the progress bar at the bottom the code in order to see the progress.\n",
    "The following code, measure the VADER sentiment as well as the RoBERTa sentiment into dictionary format and in the next cell they are combined with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1399dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0761e25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 119995/119995 [1:29:31<00:00, 22.34it/s]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df_train_for_transformer.iterrows(), total=len(df_train_for_transformer)):\n",
    "    try:\n",
    "        text = row['Full Text2']\n",
    "        myid = row['index']\n",
    "# input the text in the above defined function for VADER sentiment        \n",
    "        vader_result = analyzer.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "# input the text in the above defined function for RoBERTa sentiment  \n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3040b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformer_result_train = pd.DataFrame(res).T\n",
    "df_transformer_result_train = df_transformer_result_train.reset_index()\n",
    "df_transformer_result_train = df_transformer_result_train.merge(df_train_for_transformer, how='left', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fa5ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b10a1d72",
   "metadata": {},
   "source": [
    "# Running Sentiment Transformer on Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26e1a7f",
   "metadata": {},
   "source": [
    "The same process as above is run on the Test setn and the 43rd election dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc07382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a2baf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 30078/30078 [28:48<00:00, 17.41it/s]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(df_test_for_transformer.iterrows(), total=len(df_test_for_transformer)):\n",
    "    try:\n",
    "        text = row['Full Text']\n",
    "        myid = row['index']\n",
    "        vader_result = analyzer.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62c0a57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformer_result_test = pd.DataFrame(res).T\n",
    "df_transformer_result_test = df_transformer_result_test.reset_index()\n",
    "df_transformer_result_test = df_transformer_result_test.merge(df_test_for_transformer, how='left', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97073235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the resulted dataset for backup purpose and also input for the visualization notebook\n",
    "df_transformer_result_train.to_csv('Data/df_transformer_result_train.csv')\n",
    "df_transformer_result_test.to_csv('Data/df_transformer_result_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18b6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68435261",
   "metadata": {},
   "source": [
    "# Running Sentiment Transformer on 43rd election Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5d80151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 35945/35945 [35:01<00:00, 17.10it/s]\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for i, row in tqdm(elxn43_for_transformer.iterrows(), total=len(elxn43_for_transformer)):\n",
    "    try:\n",
    "        text = row['Full Text']\n",
    "        myid = row['index']\n",
    "        vader_result = analyzer.polarity_scores(text)\n",
    "        vader_result_rename = {}\n",
    "        for key, value in vader_result.items():\n",
    "            vader_result_rename[f\"vader_{key}\"] = value\n",
    "        roberta_result = polarity_scores_roberta(text)\n",
    "        both = {**vader_result_rename, **roberta_result}\n",
    "        res[myid] = both\n",
    "    except RuntimeError:\n",
    "        print(f'Broke for id {myid}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cda3f162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformer_result_elxn43 = pd.DataFrame(res).T\n",
    "df_transformer_result_elxn43 = df_transformer_result_elxn43.reset_index()\n",
    "df_transformer_result_elxn43 = df_transformer_result_elxn43.merge(elxn43_for_transformer, how='left', on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89d143b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the resulted dataset for backup purpose and also input for the visualization notebook\n",
    "df_transformer_result_elxn43.to_csv('Data/df_transformer_result_elxn43.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e7f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code",
   "language": "python",
   "name": "code"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
